import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline

dataset = pd.read_csv('C:/Users/Som/Desktop/Project/tumor.data',header=None)
dataset.head()

dataset.columns = ['Class','Age','Sex','Histological Type','Degree','Bone','Bone Marrow','Lung','Pleura','Peritoneum','Liver','Brain','Skin','Neck','Supraclavicular','Axillar','Mediastinum','Abdominal']
dataset.head()

dataset.info()

dataset = dataset.dropna(axis=1)
dataset.head()

dataset = dataset.drop('Histological Type',1)
dataset.head()

dataset = dataset.drop('Age',1)
dataset.head()

dataset = dataset.dropna(axis=0)
dataset.head()

from sklearn.preprocessing import LabelEncoder 
le = LabelEncoder()
dataset['Class'] = le.fit_transform(dataset['Class'])
dataset.head()

dataset.describe()

dataset.corr()

X = dataset.iloc[:,0:1].values # independent
y = dataset.iloc[:,-1].values # dependent 
X.shape, y.shape

col = dataset.keys()
col

import seaborn as sns
corr = dataset.corr()
plt.figure(figsize=(10,10))
sns.heatmap(corr,annot=True,cmap='viridis')
plt.show()

from sklearn.cross_validation import train_test_split
x_train, x_test,y_train,y_test= train_test_split(X,y,test_size=0.5,random_state = 0)
x_train.shape, x_test.shape, y_train.shape,y_test.shape

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

model_log = LogisticRegression (C=10.0)
model_knn = KNeighborsClassifier(n_neighbors = 3)
model_svm = SVC(C=10.0,kernel='rbf')
model_dt = DecisionTreeClassifier()
model_rf = RandomForestClassifier()
model_log.fit(x_train,y_train)
model_knn.fit(x_train,y_train)
model_svm.fit(x_train,y_train)
model_dt.fit(x_train,y_train)
model_rf.fit(x_train,y_train)

y_pred_log = model_log.predict(x_test)
y_pred_knn = model_knn.predict(x_test)
y_pred_svm = model_svm.predict(x_test)
y_pred_dt = model_dt.predict(x_test)
y_pred_rf = model_rf.predict(x_test)

from sklearn.metrics import confusion_matrix, classification_report
cm_log = confusion_matrix(y_test,y_pred_log)
cm_knn = confusion_matrix(y_test,y_pred_knn)
cm_svm = confusion_matrix(y_test,y_pred_svm)
cm_dt = confusion_matrix(y_test,y_pred_dt)
cm_rf = confusion_matrix(y_test,y_pred_rf)

import seaborn as sns
plt.figure(figsize=(9,9))
sns.heatmap(cm_log,annot=True,cmap='summer')
plt.title('Logistic Regression')
plt.show()

plt.figure(figsize=(9,9))
sns.heatmap(cm_knn,annot=True,cmap='magma')
plt.title('K Nearest Neighbors')
plt.show()

plt.figure(figsize=(9,9))
sns.heatmap(cm_svm,annot=True,cmap='plasma')
plt.title('SVM')
plt.show()

plt.figure(figsize=(9,9))
sns.heatmap(cm_dt,annot=True,cmap='inferno')
plt.title('Decision Tree')
plt.show()

plt.figure(figsize=(9,9))
sns.heatmap(cm_rf,annot=True,cmap='PuRd')
plt.title('Random Forest')
plt.show()

print('\n'+"*"*20+ 'Classification Report'+ "*"*20+'\n')

cr_log = classification_report(y_test,y_pred_log)
print('\n'+"="*20+ 'Logistic Regression'+ "="*20+'\n')
print(cr_log)

cr_knn = classification_report(y_test,y_pred_knn)
print('\n'+"="*20+ 'K Nearest Neighbor'+ "="*20+'\n')
print(cr_knn)

cr_svm = classification_report(y_test,y_pred_svm)
print('\n'+"="*20+ 'Support Vector Machine'+ "="*20+'\n')
print(cr_svm)

cr_dt = classification_report(y_test,y_pred_dt)
print('\n'+"="*20+ 'Desicion Tree'+ "="*20+'\n')
print(cr_dt)

cr_rf= classification_report(y_test,y_pred_rf)
print('\n'+"="*20+ 'Random Forest'+ "="*20+'\n')
print(cr_rf)
